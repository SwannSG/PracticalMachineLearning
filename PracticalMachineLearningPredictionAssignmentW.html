<html><head><title>Practical Machine Learning - Prediction Assignment Write Up</title><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}.c7{border-bottom-width:1pt;border-top-style:solid;width:75pt;border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-bottom-style:solid;vertical-align:bottom;border-top-color:#000000;border-left-color:#000000;border-right-color:#000000;border-left-style:solid;border-right-width:1pt;border-left-width:1pt}.c1{line-height:1.15;padding-top:0pt;widows:2;orphans:2;text-align:center;direction:ltr;padding-bottom:0pt}.c5{vertical-align:baseline;color:#000000;font-size:10pt;font-style:normal;font-family:"Arial";text-decoration:none;font-weight:normal}.c12{vertical-align:baseline;color:#000000;font-style:normal;font-family:"Arial";text-decoration:none}.c6{widows:2;orphans:2;height:11pt;direction:ltr}.c17{margin-right:auto;border-collapse:collapse;margin-left:auto}.c9{widows:2;orphans:2;direction:ltr}.c16{max-width:508pt;background-color:#ffffff;padding:43.7pt 43.7pt 43.7pt 43.7pt}.c4{font-size:8pt}.c2{font-weight:bold}.c3{height:0pt}.c0{font-style:italic}.c15{height:11pt}.c11{background-color:#d9d9d9}.c8{text-decoration:underline}.c10{font-size:10pt}.c14{line-height:1.2}.c13{text-align:center}.title{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:21pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}.subtitle{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:13pt;font-family:"Trebuchet MS";padding-bottom:10pt;page-break-after:avoid}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:16pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h2{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:13pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h3{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:12pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h4{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;text-decoration:underline;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h5{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h6{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}</style></head><body class="c16"><p class="c9"><span class="c2 c8">Practical Machine Learning - Prediction Assignment Write Up</span></p><p class="c6"><span></span></p><p class="c9"><span class="c2">Summary of Problem</span></p><p class="c6"><span></span></p><p class="c9"><span>We are provided two datasets, </span><span class="c0">training data</span><span>&nbsp;and </span><span class="c0">testing data</span><span>. The output we are trying to predict is &lsquo;classe&rsquo;. We produce a prediction model that runs against the testing data and classifies the output.</span></p><p class="c6"><span></span></p><p class="c9"><span>The output &lsquo;classe&rsquo; has five categories. A or 1 indicates exercise done correctly, and B,C,D,E (2,3,4,5) exercise not done correctly. Our task is determine the &ldquo;exercise done correctly&rdquo; categorisation. &nbsp; </span></p><p class="c6"><span></span></p><p class="c9"><span class="c2">Solution</span></p><p class="c6"><span></span></p><p class="c9"><span>In order to predict against the testing dataset we need to understand what inputs are provided in the testing dataset. It is no good using inputs that are not available in the testing dataset, even though they may be available in the training dataset. </span></p><p class="c6"><span></span></p><p class="c9"><span>There are some obvious columns to immediately drop in the testing and training datasets such as </span><span class="c0">&#39;X&#39;,&#39;user_name&#39;, &#39;raw_timestamp_part_1&#39;, &#39;raw_timestamp_part_2&#39;, &#39;cvtd_timestamp&#39;, &#39;new_window&#39;, &#39;num_window&#39;</span><span>, ans </span><span class="c0">&#39;problem_id&#39;</span><span>.</span></p><p class="c6"><span></span></p><p class="c9"><span>My approach was then to find all columns in the testing dataset that contained numeric values. At that point we have a set of indicators that we know can be used for testing.</span></p><p class="c6"><span></span></p><p class="c9"><span>Next we review the training data. We again extract only numeric columns and also drop rows where </span><span class="c0">&lsquo;new_window=yes&rsquo;</span><span>&nbsp;- this because in testing data </span><span class="c0">&lsquo;new_window=no&rsquo;</span><span>. Next we extract common indicators between testing and training datasets. Having done that we know that our classification model will use indicators that are available in the testing dataset.</span></p><p class="c6"><span></span></p><p class="c9"><span>The training data is in a set sequence and because of that we first randomize the row order.</span></p><p class="c6"><span></span></p><p class="c9"><span>We now split the training data into two datasets using createDataPartition. A &ldquo;genuine&rdquo; training set (70%) &nbsp;and a validation set (30%). Later we use the validation set to test how well we believe the prediction model performs.</span></p><p class="c6"><span></span></p><p class="c9"><span>Next we fit the training data using a random forest tree model. In practice the caret </span><span class="c0">train()</span><span>&nbsp;function just took far too long and I abandoned that approach. Using </span><span class="c0">randomForest()</span><span>&nbsp;function directly was computationally much quicker.</span></p><p class="c6"><span></span></p><p class="c9"><span class="c2">Model Performance</span></p><p class="c6"><span></span></p><p class="c9"><span>The </span><span class="c0">modelFit</span><span>, the output of </span><span class="c0">randomForest(), </span><span>for the random forest model is shown below:</span></p><p class="c6"><span></span></p><p class="c9 c13 c14"><span>&nbsp; &nbsp; &nbsp; &nbsp;</span><span class="c4">OOB estimate of &nbsp;error rate: 0.52%<br>Confusion matrix:<br> &nbsp; &nbsp; A &nbsp; &nbsp;B &nbsp; &nbsp;C &nbsp; &nbsp;D &nbsp; &nbsp;E &nbsp;class.error<br>A 3830 &nbsp; &nbsp;2 &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;0 0.0005219207<br>B &nbsp; 13 2544 &nbsp; &nbsp;6 &nbsp; &nbsp;0 &nbsp; &nbsp;0 0.0074131877<br>C &nbsp; &nbsp;0 &nbsp; 17 2350 &nbsp; &nbsp;1 &nbsp; &nbsp;0 0.0076013514<br>D &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; 20 2200 &nbsp; &nbsp;3 0.0103463788<br>E &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;2 &nbsp; &nbsp;6 2458 0.0032441200</span></p><p class="c6"><span></span></p><p class="c6"><span></span></p><p class="c9"><span>As can be seen the classification appears to be extremely good.</span></p><p class="c6"><span></span></p><p class="c9"><span>Now we test model performance against the validation set. We compare prediction with actual. Before we do that, the &lsquo;classe&rsquo; factor variable is adjusted from A (1), B (2), C (3), D (4), E (5) to A (1), (B, C, D, E) (2). Remember we are testing whether the exercise is done correctly as an A (1). We bundle &ldquo;not done correctly&rdquo; into a single factor (2).</span></p><p class="c6"><span></span></p><p class="c9 c13"><span class="c4">Confusion Matrix and Statistics<br><br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Reference<br>Prediction &nbsp; &nbsp;1 &nbsp; &nbsp;2<br> &nbsp; &nbsp; &nbsp; &nbsp; 1 1634 &nbsp; &nbsp;6<br> &nbsp; &nbsp; &nbsp; &nbsp; 2 &nbsp; &nbsp;5 4119<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Accuracy : 0.9981 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 95% CI : (0.9966, 0.999)<br> &nbsp; &nbsp;No Information Rate : 0.7156 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp;P-Value [Acc &gt; NIR] : &lt;2e-16 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Kappa : 0.9953 &nbsp; &nbsp; &nbsp; &nbsp; <br> Mcnemar&#39;s Test P-Value : 1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Sensitivity : 0.9969 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Specificity : 0.9985 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; Pos Pred Value : 0.9963 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; Neg Pred Value : 0.9988 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Prevalence : 0.2844 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; Detection Rate : 0.2835 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; Detection Prevalence : 0.2845 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp;Balanced Accuracy : 0.9977 &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br> &nbsp; &nbsp; &nbsp; &#39;Positive&#39; Class : 1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c6"><span></span></p><p class="c9"><span>This is further summarised in the confusion matrix below from the validation dataset.</span></p><p class="c6"><span></span></p><p class="c9 c13"><span>Confusion Matrix</span></p><a href="#" name="f70d059da10f0b932968ac70cf970ef7d6790223"></a><a href="#" name="0"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c3"><td class="c7 c11" colspan="1" rowspan="1"><p class="c1 c15"><span class="c5"></span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c12 c2 c10">Actual</span></p><p class="c1"><span class="c2 c10">A</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c12 c2 c10">Actual</span></p><p class="c1"><span class="c2 c10">B,C,D,C</span></p></td></tr><tr class="c3"><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c2 c10 c12">Predicted</span></p><p class="c1"><span class="c2 c10">A</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c5">True Positive</span></p><p class="c1"><span class="c5">1634</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c5">False Positive</span></p><p class="c1"><span class="c5">6</span></p></td></tr><tr class="c3"><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c12 c2 c10">Predicted</span></p><p class="c1"><span class="c2 c10">B,C,D,C</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c5">False Negative</span></p><p class="c1"><span class="c5">5</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c1"><span class="c5">True Negative</span></p><p class="c1"><span class="c5">4119</span></p></td></tr></tbody></table><p class="c6"><span></span></p><p class="c9"><span>From the validation set the likelihood of an incorrect classification is around 0.2% - </span><span class="c0">(False Positive + False Negative)/ Total</span><span>. That out-of-sample error rate seems almost too good to be true, but with some certainty we can state the error rate is better than 0.5%.</span></p><p class="c6"><span></span></p><p class="c9"><span class="c2">Prediction On 20 Test Cases</span></p><p class="c6"><span></span></p><p class="c9"><span>The usefulness of a model is in how well it predicts against the testing data. All 20 cases were predicted correctly. We can conclude that the model is working satisfactorily.</span></p><p class="c9"><span>&nbsp;</span></p><p class="c6"><span></span></p><p class="c6"><span></span></p><p class="c6"><span></span></p><p class="c6"><span></span></p><p class="c9"><span class="c2">Implementation Pain</span></p><p class="c6"><span></span></p><p class="c9"><span>While the above summary may imply everything was smooth sailing, this was not the case.</span></p><p class="c6"><span></span></p><p class="c9"><span>Initially I proceeded with training data pre-processing without looking at the testing data. When I needed to predict using the test data, everything fell apart.</span></p><p class="c6"><span></span></p><p class="c9"><span>I then realised I had to first investigate how the test data looked, and use only a subset of those inputs in the training data.</span></p><p class="c6"><span></span></p><p class="c9"><span>I also realised to validate the model, and get a more reliable prediction for the out-of-sample error rates, the testing data needed to be split into </span><span class="c0">testing</span><span>&nbsp;and </span><span class="c0">validation</span><span>&nbsp;datasets.</span></p><p class="c6"><span></span></p><p class="c9"><span>The performance of the caret </span><span class="c0">train()</span><span>&nbsp;function against my training data was very poor, and that approach had to be abandoned and replaced with the </span><span class="c0">randomForest()</span><span>&nbsp;function. It took a few nights to determine that. &nbsp;</span></p><p class="c6"><span></span></p><p class="c6"><span></span></p><p class="c9 c13"><span class="c10">Diagram of Prediction Assignment</span></p><p class="c9 c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 678.00px; height: 508.00px;"><img alt="Prediction Assignement.png" src="images/image00.png" style="width: 678.00px; height: 508.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span>&nbsp; </span></p><p class="c9"><span class="c2">Working R Code</span></p><p class="c6"><span></span></p><p class="c9"><span>Code is provided in project02.R, which does the bulk of the heavy lifting. Output of files for Coursera is in answers.R. &nbsp; &nbsp; </span></p><p class="c9"><span class="c2">Indicator (Input) Column Names Used In the Model</span></p><p class="c6"><span></span></p><p class="c9"><span>&nbsp;[1] &quot;roll_belt&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;pitch_belt&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;yaw_belt&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br> [4] &quot;total_accel_belt&quot; &nbsp; &nbsp; &quot;gyros_belt_x&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;gyros_belt_y&quot; &nbsp; &nbsp; &nbsp; &nbsp;<br> [7] &quot;gyros_belt_z&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;accel_belt_x&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;accel_belt_y&quot; &nbsp; &nbsp; &nbsp; &nbsp;<br>[10] &quot;accel_belt_z&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;magnet_belt_x&quot; &nbsp; &nbsp; &nbsp; &nbsp;&quot;magnet_belt_y&quot; &nbsp; &nbsp; &nbsp; <br>[13] &quot;magnet_belt_z&quot; &nbsp; &nbsp; &nbsp; &nbsp;&quot;roll_arm&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;pitch_arm&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br>[16] &quot;yaw_arm&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;total_accel_arm&quot; &nbsp; &nbsp; &nbsp;&quot;gyros_arm_x&quot; &nbsp; &nbsp; &nbsp; &nbsp; <br>[19] &quot;gyros_arm_y&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;gyros_arm_z&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;accel_arm_x&quot; &nbsp; &nbsp; &nbsp; &nbsp; <br>[22] &quot;accel_arm_y&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;accel_arm_z&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;magnet_arm_x&quot; &nbsp; &nbsp; &nbsp; &nbsp;<br>[25] &quot;magnet_arm_y&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;magnet_arm_z&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;roll_dumbbell&quot; &nbsp; &nbsp; &nbsp; <br>[28] &quot;pitch_dumbbell&quot; &nbsp; &nbsp; &nbsp; &quot;yaw_dumbbell&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;total_accel_dumbbell&quot;<br>[31] &quot;gyros_dumbbell_x&quot; &nbsp; &nbsp; &quot;gyros_dumbbell_y&quot; &nbsp; &nbsp; &quot;gyros_dumbbell_z&quot; &nbsp; &nbsp;<br>[34] &quot;accel_dumbbell_x&quot; &nbsp; &nbsp; &quot;accel_dumbbell_y&quot; &nbsp; &nbsp; &quot;accel_dumbbell_z&quot; &nbsp; &nbsp;<br>[37] &quot;magnet_dumbbell_x&quot; &nbsp; &nbsp;&quot;magnet_dumbbell_y&quot; &nbsp; &nbsp;&quot;magnet_dumbbell_z&quot; &nbsp; <br>[40] &quot;roll_forearm&quot; &nbsp; &nbsp; &nbsp; &nbsp; &quot;pitch_forearm&quot; &nbsp; &nbsp; &nbsp; &nbsp;&quot;yaw_forearm&quot; &nbsp; &nbsp; &nbsp; &nbsp; <br>[43] &quot;total_accel_forearm&quot; &nbsp;&quot;gyros_forearm_x&quot; &nbsp; &nbsp; &nbsp;&quot;gyros_forearm_y&quot; &nbsp; &nbsp; <br>[46] &quot;gyros_forearm_z&quot; &nbsp; &nbsp; &nbsp;&quot;accel_forearm_x&quot; &nbsp; &nbsp; &nbsp;&quot;accel_forearm_y&quot; &nbsp; &nbsp; <br>[49] &quot;accel_forearm_z&quot; &nbsp; &nbsp; &nbsp;&quot;magnet_forearm_x&quot; &nbsp; &nbsp; &quot;magnet_forearm_y&quot; &nbsp; &nbsp;<br>[52] &quot;magnet_forearm_z&quot; &nbsp; &nbsp; &quot;classe&quot; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c6"><span></span></p><p class="c9"><span>Note: </span><span class="c0">&lsquo;classe&rsquo;</span><span>&nbsp;is an output</span></p><p class="c6"><span></span></p></body></html>